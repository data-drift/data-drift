{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "import os\n",
    "\n",
    "# Create a .env with the following content:\n",
    "# GH_TOKEN=your_github_token\n",
    "# REPON=$gh_org/$repo\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "# Get GitHub token from environment variable\n",
    "gh_token = os.getenv(\"GH_TOKEN\")\n",
    "if gh_token is None:\n",
    "    print(\"GitHub token not found! Create a .env file a the root with a GH_TOKEN variable.\")\n",
    "    exit(1)\n",
    "gh_client = Github(gh_token, timeout=60)\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "repo = gh_client.get_repo(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/metric_name_13.csv?token=ABUWFPYHI2WJRM4VAUF3MO3FKTL6O\n",
      "Dataframe dtypes {'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Change detected\n",
      "Update: DRIFT\n"
     ]
    },
    {
     "ename": "GithubException",
     "evalue": "422 {\"message\": \"path cannot start with a slash\", \"errors\": [{\"resource\": \"Commit\", \"field\": \"path\", \"code\": \"invalid\"}], \"documentation_url\": \"https://docs.github.com/rest/repos/contents#create-or-update-file-contents\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGithubException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Store metric for the first time\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dataMonth1 \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39mAlice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBob\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCharlie\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39m2022-12\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m2023-01\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m2023-01\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mage\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m25\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m35\u001b[39m]}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m store_table(github_client\u001b[39m=\u001b[39mgh_client,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     github_repository_name\u001b[39m=\u001b[39m repo,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     table_dataframe\u001b[39m=\u001b[39m formatDF(dataMonth1),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     table_name\u001b[39m=\u001b[39m file_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     assignees\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mSammy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/github_store_metric.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/github_connector.py:72\u001b[0m, in \u001b[0;36mstore_table\u001b[0;34m(github_client, github_repository_name, branch, assignees, table_dataframe, table_name, drift_evaluator)\u001b[0m\n\u001b[1;32m     67\u001b[0m assert_branch_exist(repo, working_branch)\n\u001b[1;32m     68\u001b[0m table_dataframe \u001b[39m=\u001b[39m sort_dataframe_on_first_column_and_assert_is_unique(\n\u001b[1;32m     69\u001b[0m     table_dataframe\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m push_metric(\n\u001b[1;32m     73\u001b[0m     table_dataframe,\n\u001b[1;32m     74\u001b[0m     assignees,\n\u001b[1;32m     75\u001b[0m     working_branch,\n\u001b[1;32m     76\u001b[0m     drift_branch,\n\u001b[1;32m     77\u001b[0m     file_path,\n\u001b[1;32m     78\u001b[0m     repo,\n\u001b[1;32m     79\u001b[0m     drift_evaluator,\n\u001b[1;32m     80\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/github_connector.py:207\u001b[0m, in \u001b[0;36mpush_metric\u001b[0;34m(dataframe, assignees, default_branch, drift_branch, file_path, repo, drift_evaluator)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     branch \u001b[39m=\u001b[39m drift_branch\n\u001b[1;32m    199\u001b[0m                 pr_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    200\u001b[0m                     pr_message\n\u001b[1;32m    201\u001b[0m                     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[39m+\u001b[39m drift_summary_string\n\u001b[1;32m    205\u001b[0m                 )\n\u001b[0;32m--> 207\u001b[0m         update_file_with_retry(\n\u001b[1;32m    208\u001b[0m             repo\u001b[39m=\u001b[39mrepo,\n\u001b[1;32m    209\u001b[0m             file_path\u001b[39m=\u001b[39mfile_path,\n\u001b[1;32m    210\u001b[0m             commit_message\u001b[39m=\u001b[39mcommit_message,\n\u001b[1;32m    211\u001b[0m             data\u001b[39m=\u001b[39mvalue[\u001b[39m\"\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto_csv(index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    212\u001b[0m             branch\u001b[39m=\u001b[39mbranch,\n\u001b[1;32m    213\u001b[0m         )\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m pr_message \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    216\u001b[0m     create_pullrequest(repo, branch, assignees, file_path, pr_message)\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/github_connector.py:255\u001b[0m, in \u001b[0;36mupdate_file_with_retry\u001b[0;34m(repo, file_path, commit_message, data, branch, max_retries)\u001b[0m\n\u001b[1;32m    253\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# Wait for 1 second before retrying\u001b[39;00m\n\u001b[1;32m    254\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    256\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to update file after \u001b[39m\u001b[39m{\u001b[39;00mmax_retries\u001b[39m}\u001b[39;00m\u001b[39m retries\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/github_connector.py:245\u001b[0m, in \u001b[0;36mupdate_file_with_retry\u001b[0;34m(repo, file_path, commit_message, data, branch, max_retries)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mcommit\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mhtml_url)\n\u001b[1;32m    244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     response \u001b[39m=\u001b[39m repo\u001b[39m.\u001b[39mupdate_file(\n\u001b[1;32m    246\u001b[0m         file_path, commit_message, data, content\u001b[39m.\u001b[39msha, branch\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m     \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mcommit\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mhtml_url)\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/github/Repository.py:2154\u001b[0m, in \u001b[0;36mRepository.update_file\u001b[0;34m(self, path, message, content, sha, branch, committer, author)\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m committer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m github\u001b[39m.\u001b[39mGithubObject\u001b[39m.\u001b[39mNotSet:\n\u001b[1;32m   2152\u001b[0m     put_parameters[\u001b[39m\"\u001b[39m\u001b[39mcommitter\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m committer\u001b[39m.\u001b[39m_identity\n\u001b[0;32m-> 2154\u001b[0m headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requester\u001b[39m.\u001b[39mrequestJsonAndCheck(\n\u001b[1;32m   2155\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPUT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2156\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m/contents/\u001b[39m\u001b[39m{\u001b[39;00murllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39mquote(path)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2157\u001b[0m     \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mput_parameters,\n\u001b[1;32m   2158\u001b[0m )\n\u001b[1;32m   2160\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m   2161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcommit\u001b[39m\u001b[39m\"\u001b[39m: github\u001b[39m.\u001b[39mCommit\u001b[39m.\u001b[39mCommit(\n\u001b[1;32m   2162\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requester, headers, data[\u001b[39m\"\u001b[39m\u001b[39mcommit\u001b[39m\u001b[39m\"\u001b[39m], completed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2166\u001b[0m     ),\n\u001b[1;32m   2167\u001b[0m }\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/github/Requester.py:353\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequestJsonAndCheck\u001b[39m(\u001b[39mself\u001b[39m, verb, url, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__check(\n\u001b[1;32m    354\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequestJson(\n\u001b[1;32m    355\u001b[0m             verb, url, parameters, headers, \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__customConnection(url)\n\u001b[1;32m    356\u001b[0m         )\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/github/Requester.py:378\u001b[0m, in \u001b[0;36mRequester.__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    376\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__structuredFromJson(output)\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m status \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__createException(status, responseHeaders, output)\n\u001b[1;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m responseHeaders, output\n",
      "\u001b[0;31mGithubException\u001b[0m: 422 {\"message\": \"path cannot start with a slash\", \"errors\": [{\"resource\": \"Commit\", \"field\": \"path\", \"code\": \"invalid\"}], \"documentation_url\": \"https://docs.github.com/rest/repos/contents#create-or-update-file-contents\"}"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.drift_evaluators\n",
    "importlib.reload(datagit.drift_evaluators)\n",
    "\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_table\n",
    "import pandas as pd\n",
    "\n",
    "## Test with file already existing and splitting new data and historical data\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "\n",
    "def formatDF(dict):\n",
    "    df = pd.DataFrame(dict)\n",
    "    df['unique_key'] = df.apply(lambda row: row['date'] + '-' + row['name'], axis=1)\n",
    "    column_order = ['unique_key'] + [col for col in df.columns if col != 'unique_key']\n",
    "    df = df.reindex(columns=column_order)\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = \"/path/to/metric_name_13.csv\"\n",
    "\n",
    "# Store metric for the first time\n",
    "dataMonth1 = {\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"date\": [\"2022-12\",\"2023-01\",\"2023-01\"], \"age\": [25, 30, 35]}\n",
    "store_table(\n",
    "    github_client=gh_client,\n",
    "    github_repository_name= repo,\n",
    "    table_dataframe= formatDF(dataMonth1),\n",
    "    table_name= file_path,\n",
    "    assignees=[\"Sammy\"]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/metric_name_13.csv?token=ABUWFP4DV3KQ7XRYD2DPVG3FKOTP6\n",
      "Dataframe dtypes {'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Change detected\n",
      "Update: NEW DATA\n",
      "https://github.com/Samox/data-history/commit/057b8159c95bebe9164128e7508d2b77fafe00a2\n"
     ]
    }
   ],
   "source": [
    "# ## Introduce new data for 2023-02\n",
    "dataMonth2 = {\"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Didier\", \"Philipe\", \"Antoine\"], \"date\": [\"2022-12\",\"2023-01\",\"2023-01\",\"2023-02\",\"2023-02\",\"2023-02\"], \"age\": [25, 30, 35, 40, 40, 40]}\n",
    "store_metric(ghClient=gh_client,dataframe=  formatDF(dataMonth2),filepath= file_path, assignees=[\"Sammy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/metric_name_13.csv?token=ABUWFP77BUGFA77QUHHJY33FKOTQC\n",
      "Dataframe dtypes {'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Change detected\n",
      "Update: NEW DATA\n",
      "https://github.com/Samox/data-history/commit/a2122ae8979b0349b3ea5d8415bfded1366b5b22\n",
      "Update: DRIFT\n",
      "https://github.com/Samox/data-history/commit/933403257a5098278d013a0fac0bf0fa2213837d\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "import pandas as pd\n",
    "\n",
    "# ## Introduce new data for 2023-03 and a drift on 2020-02\n",
    "dataMonth3 = {\"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Didier\", \"Philipe\", \"Antoine\", \"Clement\", \"Cyril\", \"Victor\"], \"date\": [\"2022-12\",\"2023-01\",\"2023-01\",\"2023-02\",\"2023-02\",\"2023-02\",\"2023-03\",\"2023-03\",\"2023-03\"], \"age\": [25, 30, 36, 40, 42, 40, 45, 45, 46]}\n",
    "store_metric(ghClient=gh_client,dataframe=  formatDF(dataMonth3),filepath= file_path, assignees=[\"Sammy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MIGRATION Column Deleted': {'df':                     name     date  age\n",
       "  unique_key                            \n",
       "  2022-12-Alice      Alice  2022-12   25\n",
       "  2023-01-Bob          Bob  2023-01   30\n",
       "  2023-01-Charlie  Charlie  2023-01   35\n",
       "  2023-02-Didier    Didier  2023-02   40\n",
       "  2023-02-Philipe  Philipe  2023-02   40\n",
       "  2023-02-Antoine  Antoine  2023-02   40,\n",
       "  'has_update': False,\n",
       "  'type': <UpdateType.OTHER: 'other'>,\n",
       "  'drift_context': None,\n",
       "  'drift_evaluation': None,\n",
       "  'drift_summary': None},\n",
       " 'NEW DATA': {'df':                     name     date  age\n",
       "  unique_key                            \n",
       "  2022-12-Alice      Alice  2022-12   25\n",
       "  2023-01-Bob          Bob  2023-01   30\n",
       "  2023-01-Charlie  Charlie  2023-01   35\n",
       "  2023-02-Didier    Didier  2023-02   40\n",
       "  2023-02-Philipe  Philipe  2023-02   40\n",
       "  2023-02-Antoine  Antoine  2023-02   40\n",
       "  2023-03-Clement  Clement  2023-03   45\n",
       "  2023-03-Cyril      Cyril  2023-03   45\n",
       "  2023-03-Victor    Victor  2023-03   46,\n",
       "  'has_update': True,\n",
       "  'type': <UpdateType.OTHER: 'other'>,\n",
       "  'drift_context': None,\n",
       "  'drift_evaluation': None,\n",
       "  'drift_summary': None},\n",
       " 'DRIFT': {'df':                     name     date  age\n",
       "  unique_key                            \n",
       "  2022-12-Alice      Alice  2022-12   25\n",
       "  2023-01-Bob          Bob  2023-01   30\n",
       "  2023-01-Charlie  Charlie  2023-01   36\n",
       "  2023-02-Didier    Didier  2023-02   40\n",
       "  2023-02-Philipe  Philipe  2023-02   42\n",
       "  2023-02-Antoine  Antoine  2023-02   40\n",
       "  2023-03-Clement  Clement  2023-03   45\n",
       "  2023-03-Cyril      Cyril  2023-03   45\n",
       "  2023-03-Victor    Victor  2023-03   46,\n",
       "  'has_update': True,\n",
       "  'type': <UpdateType.DRIFT: 'drift'>,\n",
       "  'drift_context': {'before':                     name     date  age\n",
       "   unique_key                            \n",
       "   2022-12-Alice      Alice  2022-12   25\n",
       "   2023-01-Bob          Bob  2023-01   30\n",
       "   2023-01-Charlie  Charlie  2023-01   35\n",
       "   2023-02-Didier    Didier  2023-02   40\n",
       "   2023-02-Philipe  Philipe  2023-02   40\n",
       "   2023-02-Antoine  Antoine  2023-02   40\n",
       "   2023-03-Clement  Clement  2023-03   45\n",
       "   2023-03-Cyril      Cyril  2023-03   45\n",
       "   2023-03-Victor    Victor  2023-03   46,\n",
       "   'after':                     name     date  age\n",
       "   unique_key                            \n",
       "   2022-12-Alice      Alice  2022-12   25\n",
       "   2023-01-Bob          Bob  2023-01   30\n",
       "   2023-01-Charlie  Charlie  2023-01   36\n",
       "   2023-02-Didier    Didier  2023-02   40\n",
       "   2023-02-Philipe  Philipe  2023-02   42\n",
       "   2023-02-Antoine  Antoine  2023-02   40\n",
       "   2023-03-Clement  Clement  2023-03   45\n",
       "   2023-03-Cyril      Cyril  2023-03   45\n",
       "   2023-03-Victor    Victor  2023-03   46,\n",
       "   'summary': {'added_rows': Empty DataFrame\n",
       "    Columns: [name, date, age]\n",
       "    Index: [],\n",
       "    'deleted_rows': Empty DataFrame\n",
       "    Columns: [name, date, age]\n",
       "    Index: [],\n",
       "    'modified_rows_unique_keys': Index(['2023-01-Charlie', '2023-02-Philipe'], dtype='object', name='unique_key'),\n",
       "    'modified_patterns':          unique_keys column  old_value  new_value           pattern_id\n",
       "    0  [2023-01-Charlie]    age         35         36  8178805064014946622\n",
       "    1  [2023-02-Philipe]    age         40         42  1251073461589937957}},\n",
       "  'drift_evaluation': {'should_alert': False,\n",
       "   'message': 'Drift detected:\\n- üÜï 0 addition\\n- ‚ôªÔ∏è 2 modifications\\n- üóëÔ∏è 0 deletion'},\n",
       "  'drift_summary': {'added_rows': Empty DataFrame\n",
       "   Columns: [name, date, age]\n",
       "   Index: [],\n",
       "   'deleted_rows': Empty DataFrame\n",
       "   Columns: [name, date, age]\n",
       "   Index: [],\n",
       "   'modified_rows_unique_keys': Index(['2023-01-Charlie', '2023-02-Philipe'], dtype='object', name='unique_key'),\n",
       "   'modified_patterns':          unique_keys column  old_value  new_value           pattern_id\n",
       "   0  [2023-01-Charlie]    age         35         36  8178805064014946622\n",
       "   1  [2023-02-Philipe]    age         40         42  1251073461589937957}},\n",
       " 'MIGRATION Column Added': {'df':                     name     date  age\n",
       "  unique_key                            \n",
       "  2022-12-Alice      Alice  2022-12   25\n",
       "  2023-01-Bob          Bob  2023-01   30\n",
       "  2023-01-Charlie  Charlie  2023-01   36\n",
       "  2023-02-Didier    Didier  2023-02   40\n",
       "  2023-02-Philipe  Philipe  2023-02   42\n",
       "  2023-02-Antoine  Antoine  2023-02   40\n",
       "  2023-03-Clement  Clement  2023-03   45\n",
       "  2023-03-Cyril      Cyril  2023-03   45\n",
       "  2023-03-Victor    Victor  2023-03   46,\n",
       "  'has_update': False,\n",
       "  'type': <UpdateType.OTHER: 'other'>,\n",
       "  'drift_context': None,\n",
       "  'drift_evaluation': None,\n",
       "  'drift_summary': None}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datagit.dataframe_update_breakdown import dataframe_update_breakdown\n",
    "\n",
    "\n",
    "dataframe_update_breakdown(initial_dataframe=formatDF(dataMonth2), final_dataframe=formatDF(dataMonth3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/metric_name_13.csv?token=ABUWFP32VEW5E7MJQOA5ZK3FKOTQK\n",
      "Dataframe dtypes {'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Change detected\n",
      "Update: DRIFT\n",
      "Branch drift/2023-11-14-17-56-39/path-to-metric-name-13-csv doesn't exist, creating it...\n",
      "Checkout branch: drift/2023-11-14-17-56-39/path-to-metric-name-13-csv  from default branch:main\n",
      "https://github.com/Samox/data-history/commit/a9183249ebb64a258d8fa074e0f22c607590d3e8\n",
      "Pull request created: https://github.com/Samox/data-history/pull/178\n",
      "Assignee Sammy does not exist\n"
     ]
    }
   ],
   "source": [
    "# ## No new data. Adds a drift for Philipe, and remove all other drifts\n",
    "from datagit.drift_evaluators import alert_drift\n",
    "\n",
    "\n",
    "dataMonth3And1Day = {\"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Didier\", \"Philipe\", \"Antoine\", \"Clement\", \"Cyril\", \"Victor\"], \"date\": [\"2022-12\",\"2023-01\",\"2023-01\",\"2023-02\",\"2023-02\",\"2023-02\",\"2023-03\",\"2023-03\",\"2023-03\"], \"age\": [25, 30, 35, 40, 42, 40, 45, 45, 46]}\n",
    "store_metric(ghClient=gh_client, dataframe= formatDF(dataMonth3And1Day),filepath= file_path, assignees=[\"Sammy\"], drift_evaluator=alert_drift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/metric_name_13.csv?token=ABUWFP2X5GXLWGHLLFWOTRLFKOTQY\n",
      "Dataframe dtypes {'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'name': string[python], 'date': string[python], 'age': string[python]}\n",
      "Change detected\n",
      "Update: DRIFT\n",
      "Branch drift/2023-11-14-17-56-47/path-to-metric-name-13-csv doesn't exist, creating it...\n",
      "Checkout branch: drift/2023-11-14-17-56-47/path-to-metric-name-13-csv  from default branch:main\n",
      "https://github.com/Samox/data-history/commit/156b9a38f23cfa9c402eb66bc67f5d796d37d215\n",
      "Pull request created: https://github.com/Samox/data-history/pull/179\n",
      "Assignee Sammy does not exist\n"
     ]
    }
   ],
   "source": [
    "# ## No new data. Adds a drift for Philipe, and remove all other drifts\n",
    "dataMonth3And2Day = {\"name\": [\"Alice\", \"Alixe\", \"Bob\", \"Charlie\", \"Didier\", \"Philipe\", \"Antoine\", \"Clement\", \"Cyril\", \"Victor\"], \"date\": [\"2022-12\",\"2022-12\",\"2023-01\",\"2023-01\",\"2023-02\",\"2023-02\",\"2023-02\",\"2023-03\",\"2023-03\",\"2023-03\"], \"age\": [25, 25, 30, 35, 40, 42, 40, 45, 45, 46]}\n",
    "store_metric(ghClient=gh_client, dataframe= formatDF(dataMonth3And2Day), filepath=file_path, assignees=[\"Sammy\"], drift_evaluator=alert_drift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  unique_key        date  metric_value\n",
      "0       95463292-2130-4f6e-ba8e-68a3ec119203  2020-09-07          2.69\n",
      "1       eca12da9-6693-4d5e-b3de-09fd34985b9a  2021-02-11          1.51\n",
      "2       efcf9b75-dac0-4c36-a669-3682ad278554  2003-09-15          0.94\n",
      "3       bb2701a9-162c-4ece-8a08-6cd9073e2847  2002-04-10          9.68\n",
      "4       162bce39-b269-4f68-887b-148df90ea90d  1997-01-11          3.89\n",
      "...                                      ...         ...           ...\n",
      "599995  60244023-edcb-40b5-b18e-d59398ec66ca  2016-02-28          0.82\n",
      "599996  62f84b8c-8a98-4c82-9cde-bcdda4216a8f  2013-01-18          0.34\n",
      "599997  d89b7270-0ee9-4a29-9788-1fd540b0d6b3  1996-02-23          4.76\n",
      "599998  e0c3da68-cee3-419d-afea-9ce4a27a50bf  2008-02-10          5.35\n",
      "599999  5524904c-75c4-4e44-a9e7-5aab97b99d34  2009-06-22          6.51\n",
      "\n",
      "[600000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker to generate random data\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows for the dataframe\n",
    "num_rows = 600000\n",
    "\n",
    "# Generate random IDs and dates\n",
    "ids = [fake.uuid4() for _ in range(num_rows)]\n",
    "dates = [fake.date_between(start_date='-30y', end_date='today').strftime('%Y-%m-%d') for _ in range(num_rows)]\n",
    "\n",
    "# Generate random metric values between 0 and 10\n",
    "metric_values = [round(random.uniform(0, 10),2) for _ in range(num_rows)]\n",
    "\n",
    "# Create the dataframe\n",
    "ultra_large_df = pd.DataFrame({'unique_key': ids, 'date': dates, 'metric_value': metric_values})\n",
    "\n",
    "# Print the dataframe\n",
    "print(ultra_large_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name3.csv?token=ABUWFP4GI2QDFSR6JLAGBZLFKOTSG\n",
      "Dataframe dtypes {'date': string[python], 'metric_value': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python]}\n",
      "Change detected\n",
      "Update: DRIFT\n",
      "https://github.com/Samox/data-history/commit/2a661fa5e3f28996abcfce12eb50b95c785633ad\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "import pandas as pd\n",
    "\n",
    "## Test with file already existing and splitting new data and historical data\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "store_metric(ghClient=gh_client,  dataframe=ultra_large_df, filepath=repo+\"/path/to/ultra_large_metric_name3.csv\", assignees=[\"Sammy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultra_large_df = ultra_large_df.iloc[:-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
