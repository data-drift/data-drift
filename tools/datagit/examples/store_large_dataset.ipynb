{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "import os\n",
    "\n",
    "# Create a .env with the following content:\n",
    "# GH_TOKEN=your_github_token\n",
    "# REPON=$gh_org/$repo\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "# Get GitHub token from environment variable\n",
    "gh_token = os.getenv(\"GH_TOKEN\")\n",
    "if gh_token is None:\n",
    "    print(\"GitHub token not found! Create a .env file a the root with a GH_TOKEN variable.\")\n",
    "    exit(1)\n",
    "gh_client = Github(gh_token, timeout=60)\n",
    "\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "repo = gh_client.get_repo(repo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  unique_key        date  metric_value  \\\n",
      "0       860ed722-b911-4959-870a-a74ab0c5f1dd  2023-01-13          1.80   \n",
      "1       92ca45d3-e7b2-46ee-b687-b0221d6576c2  2023-03-14          3.87   \n",
      "2       338dce4a-335d-4299-8eb2-c6d607f0e62c  2022-12-27          5.30   \n",
      "3       8a4b715c-e66e-421e-b2f8-891ad05a775d  2023-02-24          5.14   \n",
      "4       f90ce9db-c1ba-4018-a260-1e8c9420138c  2023-03-10          0.12   \n",
      "...                                      ...         ...           ...   \n",
      "599995  3ae11d82-997b-4fa2-af16-6a65bd330377  2023-03-13          2.35   \n",
      "599996  c73ad3a7-4719-42ce-940d-f61bd948b8d4  2023-07-24          9.35   \n",
      "599997  1d066518-70e3-40d1-9086-2450aee7ab4f  2023-05-14          5.20   \n",
      "599998  53fa243c-69c5-4904-bfe8-7b8b80aab7b5  2023-04-21          2.20   \n",
      "599999  4dabb531-c820-4b45-99ec-729cb6e1042f  2022-12-09          6.08   \n",
      "\n",
      "       country_code    category  \n",
      "0                AF  Category A  \n",
      "1                BY  Category A  \n",
      "2                CN  Category A  \n",
      "3                RW  Category B  \n",
      "4                GY  Category A  \n",
      "...             ...         ...  \n",
      "599995           SR  Category A  \n",
      "599996           EE  Category C  \n",
      "599997           GE  Category A  \n",
      "599998           MM  Category C  \n",
      "599999           NA  Category A  \n",
      "\n",
      "[600000 rows x 5 columns]\n",
      "Size of DataFrame in bytes: 40140032\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker to generate random data\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows for the dataframe\n",
    "num_rows = 600000\n",
    "\n",
    "# Generate random IDs and dates\n",
    "ids = [fake.uuid4() for _ in range(num_rows)]\n",
    "dates = [fake.date_between(start_date='-1y', end_date='-1m').strftime('%Y-%m-%d') for _ in range(num_rows)]\n",
    "\n",
    "# Generate random metric values between 0 and 10\n",
    "metric_values = [round(random.uniform(0, 10),2) for _ in range(num_rows)]\n",
    "# Generate random country codes\n",
    "country_codes = [fake.country_code() for _ in range(num_rows)]\n",
    "\n",
    "# Generate random categories\n",
    "categories = [random.choice(['Category A', 'Category B', 'Category C']) for _ in range(num_rows)]\n",
    "\n",
    "# Create the dataframe\n",
    "ultra_large_df = pd.DataFrame({'unique_key': ids, 'date': dates, 'metric_value': metric_values, 'country_code': country_codes, 'category': categories})\n",
    "\n",
    "# Print the dataframe\n",
    "print(ultra_large_df)\n",
    "local_file_path = 'ultra_large_df.csv'\n",
    "ultra_large_df.to_csv(local_file_path, index=False)\n",
    "print('Size of DataFrame in bytes:', os.path.getsize(local_file_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitionning metric...\n",
      "Storing metric for Month: 2022-09-30 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2022-09.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2022-10-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2022-10.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2022-11-30 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2022-11.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2022-12-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2022-12.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-01-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-01.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-02-28 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-02.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-03-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-03.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-04-30 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-04.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-05-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-05.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-06-30 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-06.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-07-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-07.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-08-31 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-08.csv\n",
      "Metric stored\n",
      "Storing metric for Month: 2023-09-30 00:00:00\n",
      "Storing metric...\n",
      "data-history Samox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric not found, creating it on branch: main\n",
      "Commit: New data: path/to/ultra_large_metric_name19/2023-09.csv\n",
      "Metric stored\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import partition_and_store_metric\n",
    "\n",
    "## Test with file already existing and splitting new data and historical data\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "file_path = repo+\"/path/to/ultra_large_metric_name19.csv\"\n",
    "partition_and_store_metric(gh_client,  ultra_large_df, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4242  60608 392832  41643 464234 122681  10258 199077 303125 520722\n",
      " 589338 285923 340236 339287 170118 520994 591772 550478 455232 123979\n",
      " 354761 254889 470580 181624 274417 328726 504212 356040  23352 214898\n",
      " 361248 277103 285786 356048  23550 236107 256942 509629 225513 564335\n",
      " 184036 354122 408248 516338 367441 413740 222624 558355 350732  39333\n",
      " 281914 445136 158145 571695  68129 364739 451960 551108 127251 528991\n",
      " 179870 101684 296154 579076 578190 404752  22682 336015 431689 505472\n",
      " 470965 267651 454329 439546 337991 326490 521320 586039 460422 513493\n",
      "  29421 382580  56964  40928  17648 511244  31867 208736 367384 157223\n",
      " 503369 483668  45568 248656 413335  14685 460849  72643 396418 483375]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "ultra_large_df2 = ultra_large_df.copy()\n",
    "\n",
    "# Select 10 random indices for metric value update\n",
    "random_indices_metric = np.random.choice(ultra_large_df2.index, size=100, replace=False)\n",
    "print(random_indices_metric)\n",
    "# Update metric value with random values between 0 and 10\n",
    "ultra_large_df2.loc[random_indices_metric, 'metric_value'] = [round(random.uniform(0, 10),2) for _ in range(100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key       object\n",
       "date             object\n",
       "metric_value    float64\n",
       "country_code     object\n",
       "category         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_large_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitionning metric...\n",
      "Storing metric for Month: 2022-09-30 00:00:00\n",
      "Storing metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name19/2022-09.csv?token=ABUWFP7MELFZF44M4Q62HKDFBK3HI\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch drift/2023-09-20-11-07-03/path-to-ultra-large-metric-name19-202 doesn't exist, creating it...\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "4750f7e9-72d6-40ab-8aa2-6ac15061d591         4.96  6.72\n",
      "ddae1540-2aae-47ad-8fc7-ed63e4b6f9eb         4.05  0.17\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': False, 'message': 'Drift detected and automatically merged.'}\n",
      "No alert needed, pushing on reported branch\n",
      "Commit: Drift: path/to/ultra_large_metric_name19/2022-09.csv\n",
      "https://github.com/Samox/data-history/commit/a55ef4f788c51fa3e4a268875d80839e21998ef8\n",
      "Drift pushed on reported branch\n",
      "Storing metric for Month: 2022-10-31 00:00:00\n",
      "Storing metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name19/2022-10.csv?token=ABUWFP3NE4KUYYXXPIR6V6TFBK3HS\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch drift/2023-09-20-11-07-09/path-to-ultra-large-metric-name19-202 doesn't exist, creating it...\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "27bd355e-209e-4cef-aaab-60b40c5f8df3          6.5  1.89\n",
      "49427e08-99d7-49d6-bb5d-96ab594c11e8         9.25   1.7\n",
      "82b2c47d-ae15-4565-bcac-590eee69510e         2.18  5.35\n",
      "e2208052-80f0-4d0c-acae-9e7e6eed202e         0.72   4.7\n",
      "e2460262-c364-41fa-aeae-c294ccd3fa55         9.29  9.79\n",
      "ef789353-244b-434b-a283-06e99b230f2f         7.89  9.88\n",
      "eff17ed7-d1bb-4247-9210-84bf9ca08927         7.03  6.38\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': False, 'message': 'Drift detected and automatically merged.'}\n",
      "No alert needed, pushing on reported branch\n",
      "Commit: Drift: path/to/ultra_large_metric_name19/2022-10.csv\n",
      "https://github.com/Samox/data-history/commit/6ed302752ac020018416dc024d7e4b4098813740\n",
      "Drift pushed on reported branch\n",
      "Storing metric for Month: 2022-11-30 00:00:00\n",
      "Storing metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name19/2022-11.csv?token=ABUWFPZIW2P2FHJAQ75LPDTFBK3IA\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch drift/2023-09-20-11-07-15/path-to-ultra-large-metric-name19-202 doesn't exist, creating it...\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "725597fe-7268-4d89-98e4-60853182b464          2.3  6.49\n",
      "8555db80-1540-4db9-b632-4793ecbbf9a5         0.69  2.55\n",
      "94148f2a-89ab-43dd-8200-870ca42f1e99         5.91  8.42\n",
      "c7c86b16-1512-491a-85e7-59ec9249f225         2.09  6.57\n",
      "e9101650-6c64-4e26-9bef-722b66554bbd          4.4  1.57\n",
      "ea43659f-84a4-4fe9-b25a-7963278f3f31         6.05  9.89\n",
      "fdda2da3-381a-43a5-9a48-144cf9b107be         7.64  7.04\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': False, 'message': 'Drift detected and automatically merged.'}\n",
      "No alert needed, pushing on reported branch\n",
      "Commit: Drift: path/to/ultra_large_metric_name19/2022-11.csv\n",
      "https://github.com/Samox/data-history/commit/64066442a0f568effabacacf161a0c858a3a8765\n",
      "Drift pushed on reported branch\n",
      "Storing metric for Month: 2022-12-31 00:00:00\n",
      "Storing metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name19/2022-12.csv?token=ABUWFP2PAAVMSXM2URRXPDLFBK3IM\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch drift/2023-09-20-11-07-21/path-to-ultra-large-metric-name19-202 doesn't exist, creating it...\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "44bb0007-d067-45e5-a846-c47d588b1840         7.94  8.71\n",
      "57d0c7ff-a1a0-4a8a-970e-c46849e09c0c         9.64  8.67\n",
      "6d7d12ed-f5b9-4683-a99c-3122081174f8          2.1  9.15\n",
      "99953e5b-b4c3-4dc6-b65c-5a0e9d3c0559         8.78  2.13\n",
      "d0e75604-70bf-4695-91c3-cce69863ea30         7.99  1.02\n",
      "ebeab420-3331-4612-8607-84c578e7d381         9.64  0.37\n",
      "fbe64076-bc54-4922-9960-45400ae9faf7         9.12  9.77\n",
      "ff985320-bea4-4d4b-bfeb-3aabde2f61cc         5.98  6.07\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': False, 'message': 'Drift detected and automatically merged.'}\n",
      "No alert needed, pushing on reported branch\n",
      "Commit: Drift: path/to/ultra_large_metric_name19/2022-12.csv\n",
      "https://github.com/Samox/data-history/commit/e7ae4e2228798ce50476198fbe647852bfa1daf6\n",
      "Drift pushed on reported branch\n",
      "Storing metric for Month: 2023-01-31 00:00:00\n",
      "Storing metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name19/2023-01.csv?token=ABUWFP5G4ZCMPUNTQWGU5N3FBK3IY\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch drift/2023-09-20-11-07-27/path-to-ultra-large-metric-name19-202 doesn't exist, creating it...\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "1110da90-77d1-4e94-9f76-5da27d566b6e         9.01  5.89\n",
      "22d4db18-7bef-4ee4-aa78-4f13777cc32f         2.34  8.78\n",
      "3967a3b2-681c-48fb-8b1d-fb93b2df2516         0.38  0.26\n",
      "6b8e6114-125f-45cb-a8ea-112ca5f0f3d6         6.72   9.4\n",
      "8b4ed718-e070-4fbd-94ce-37010f8953fd         3.16  1.29\n",
      "951090b8-6180-4a0a-a89f-fb23cebfacef         2.61  2.56\n",
      "96e5ba4c-0903-4592-ab41-62bd42efd876         5.22  1.68\n",
      "af58a2e8-8c97-4768-a3ca-1d5e05e7aab1         8.19  8.02\n",
      "bcf07fa5-3923-41ec-9379-aa76f9deb49c         3.93  7.04\n",
      "ec6e2e4b-46b4-4ee3-8cde-ef52487cc741         2.31  7.73\n",
      "ee4d3c0e-85cc-4fad-b62b-2dec1bdc68c0         0.57  1.25\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': False, 'message': 'Drift detected and automatically merged.'}\n",
      "No alert needed, pushing on reported branch\n",
      "Commit: Drift: path/to/ultra_large_metric_name19/2023-01.csv\n",
      "https://github.com/Samox/data-history/commit/af3fd95aa08bc62e9639a0471186e2599a2c8367\n",
      "Drift pushed on reported branch\n",
      "Storing metric for Month: 2023-02-28 00:00:00\n",
      "Storing metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/dataset_helpers.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column] = formatted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name19/2023-02.csv?token=ABUWFP5MSWUURD37H522KH3FBK3JE\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch drift/2023-09-20-11-07-34/path-to-ultra-large-metric-name19-202 doesn't exist, creating it...\n"
     ]
    },
    {
     "ename": "GithubException",
     "evalue": "422 {\"message\": \"Reference already exists\", \"documentation_url\": \"https://docs.github.com/rest/git/refs#create-a-reference\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGithubException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/store_large_dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/store_large_dataset.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m importlib\u001b[39m.\u001b[39mreload(datagit\u001b[39m.\u001b[39mgithub_connector)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/store_large_dataset.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatagit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgithub_connector\u001b[39;00m \u001b[39mimport\u001b[39;00m partition_and_store_metric\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/store_large_dataset.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m partition_and_store_metric(gh_client,  ultra_large_df2, file_path, assignees\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mSammy\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/github_connector.py:122\u001b[0m, in \u001b[0;36mpartition_and_store_metric\u001b[0;34m(ghClient, dataframe, filepath, assignees, store_json, drift_evaluator)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring metric for Month: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m monthly_filepath \u001b[39m=\u001b[39m get_monthly_file_path(filepath, name\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 122\u001b[0m store_metric(\n\u001b[1;32m    123\u001b[0m     ghClient, group, monthly_filepath, assignees, store_json, drift_evaluator\n\u001b[1;32m    124\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/github_connector.py:63\u001b[0m, in \u001b[0;36mstore_metric\u001b[0;34m(ghClient, dataframe, filepath, assignees, store_json, drift_evaluator)\u001b[0m\n\u001b[1;32m     60\u001b[0m repo \u001b[39m=\u001b[39m ghClient\u001b[39m.\u001b[39mget_repo(repo_orga \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m repo_name)\n\u001b[1;32m     61\u001b[0m dataframe \u001b[39m=\u001b[39m sort_dataframe_on_first_column_and_assert_is_unique(dataframe)\n\u001b[0;32m---> 63\u001b[0m push_metric(\n\u001b[1;32m     64\u001b[0m     dataframe,\n\u001b[1;32m     65\u001b[0m     assignees,\n\u001b[1;32m     66\u001b[0m     repo\u001b[39m.\u001b[39;49mdefault_branch,\n\u001b[1;32m     67\u001b[0m     drift_branch,\n\u001b[1;32m     68\u001b[0m     store_json,\n\u001b[1;32m     69\u001b[0m     file_path,\n\u001b[1;32m     70\u001b[0m     repo,\n\u001b[1;32m     71\u001b[0m     drift_evaluator,\n\u001b[1;32m     72\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/github_connector.py:181\u001b[0m, in \u001b[0;36mpush_metric\u001b[0;34m(dataframe, assignees, default_branch, drift_branch, store_json, file_path, repo, drift_evaluator)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNew data found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m     push_new_lines(\n\u001b[1;32m    174\u001b[0m         file_path,\n\u001b[1;32m    175\u001b[0m         repo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m         store_json,\n\u001b[1;32m    179\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m checkout_branch_from_default_branch(repo, drift_branch)\n\u001b[1;32m    182\u001b[0m should_push_drift \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/DataDrift/data-drift/tools/datagit/examples/../datagit/github_connector.py:475\u001b[0m, in \u001b[0;36mcheckout_branch_from_default_branch\u001b[0;34m(repo, branch_name)\u001b[0m\n\u001b[1;32m    472\u001b[0m default_branch \u001b[39m=\u001b[39m repo\u001b[39m.\u001b[39mget_branch(repo\u001b[39m.\u001b[39mdefault_branch)\n\u001b[1;32m    474\u001b[0m \u001b[39m# Create a new reference to the default branch\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m ref \u001b[39m=\u001b[39m repo\u001b[39m.\u001b[39;49mcreate_git_ref(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrefs/heads/\u001b[39;49m\u001b[39m{\u001b[39;49;00mbranch_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, default_branch\u001b[39m.\u001b[39;49mcommit\u001b[39m.\u001b[39;49msha)\n\u001b[1;32m    477\u001b[0m \u001b[39mreturn\u001b[39;00m ref\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/github/Repository.py:970\u001b[0m, in \u001b[0;36mRepository.create_git_ref\u001b[0;34m(self, ref, sha)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(sha, \u001b[39mstr\u001b[39m), sha\n\u001b[1;32m    966\u001b[0m post_parameters \u001b[39m=\u001b[39m {\n\u001b[1;32m    967\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mref\u001b[39m\u001b[39m\"\u001b[39m: ref,\n\u001b[1;32m    968\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msha\u001b[39m\u001b[39m\"\u001b[39m: sha,\n\u001b[1;32m    969\u001b[0m }\n\u001b[0;32m--> 970\u001b[0m headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requester\u001b[39m.\u001b[39;49mrequestJsonAndCheck(\n\u001b[1;32m    971\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl\u001b[39m}\u001b[39;49;00m\u001b[39m/git/refs\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mpost_parameters\n\u001b[1;32m    972\u001b[0m )\n\u001b[1;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m github\u001b[39m.\u001b[39mGitRef\u001b[39m.\u001b[39mGitRef(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requester, headers, data, completed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/github/Requester.py:353\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequestJsonAndCheck\u001b[39m(\u001b[39mself\u001b[39m, verb, url, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__check(\n\u001b[1;32m    354\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequestJson(\n\u001b[1;32m    355\u001b[0m             verb, url, parameters, headers, \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__customConnection(url)\n\u001b[1;32m    356\u001b[0m         )\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/github/Requester.py:378\u001b[0m, in \u001b[0;36mRequester.__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    376\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__structuredFromJson(output)\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m status \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__createException(status, responseHeaders, output)\n\u001b[1;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m responseHeaders, output\n",
      "\u001b[0;31mGithubException\u001b[0m: 422 {\"message\": \"Reference already exists\", \"documentation_url\": \"https://docs.github.com/rest/git/refs#create-a-reference\"}"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "\n",
    "import datagit.drift_evaluators\n",
    "importlib.reload(datagit.drift_evaluators)\n",
    "from datagit.drift_evaluators import default_drift_evaluator\n",
    "\n",
    "\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import partition_and_store_metric\n",
    "\n",
    "\n",
    "partition_and_store_metric(gh_client,  ultra_large_df2, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows for the dataframe\n",
    "num_rows = 6000\n",
    "\n",
    "# Generate random IDs and dates\n",
    "ids = [fake.uuid4() for _ in range(num_rows)]\n",
    "dates = [fake.date_between(start_date='-1m', end_date='today').strftime('%Y-%m-%d') for _ in range(num_rows)]\n",
    "\n",
    "# Generate random metric values between 0 and 10\n",
    "metric_values = [round(random.uniform(0, 10),2) for _ in range(num_rows)]\n",
    "# Generate random country codes\n",
    "country_codes = [fake.country_code() for _ in range(num_rows)]\n",
    "\n",
    "# Generate random categories\n",
    "categories = [random.choice(['Category A', 'Category B', 'Category C']) for _ in range(num_rows)]\n",
    "\n",
    "# Create the dataframe\n",
    "new_lines = pd.DataFrame({'unique_key': ids, 'date': dates, 'metric_value': metric_values, 'country_code': country_codes, 'category': categories})\n",
    "\n",
    "ultra_large_df3 = pd.concat([ultra_large_df2, new_lines], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: main\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/main/path/to/ultra_large_metric_name18.csv?token=ABUWFP5KQIF72QPM6CKZ6VTEW2IZK\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "New data found\n",
      "Commit: New data: path/to/ultra_large_metric_name18.csv\n",
      "https://github.com/Samox/data-history/commit/510cc1a3978ec68cc439c5f19088d9626eb0db2f\n",
      "Branch metric/path-to-ultra-large-metric-name18-csv doesn't exist, creating it...\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "03aeb072-4c9b-4900-a65f-0cb012459f50         5.28  2.02\n",
      "0500de9f-7c2c-4c7a-8f6e-7d2be08551a0         7.35  4.17\n",
      "0b1e939d-15d8-446f-82e0-0774a42b6e38         8.08  1.18\n",
      "0dbaf1fc-88be-4641-8d79-914939080efe         5.51  3.34\n",
      "0fe39883-35c3-45c9-bcff-e84caf85ff39         4.96  0.21\n",
      "...                                           ...   ...\n",
      "ea4f01d7-1c35-406f-830e-f72218d76617         2.99   6.7\n",
      "efa5f736-759e-477a-bc60-ee39a6acf360         5.99  1.34\n",
      "f096b302-e842-48b0-8d73-9eac7917c5fb         7.66  6.84\n",
      "f7a7d70b-f652-4503-acd6-df3fe7e1ab70          9.6  1.51\n",
      "fcdcf0f6-eeb6-43f7-82d7-512c27926639         5.15  8.64\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': True, 'message': 'Drift detected:\\n- ~~🆕 0 addition~~\\n- ♻️ 605988 modifications\\n- ~~🗑️ 0 deletion~~'}\n",
      "Commit: Drift: path/to/ultra_large_metric_name18.csv\n",
      "https://github.com/Samox/data-history/commit/2acacfc24f637533b7a5f987a7d268d3c792a54b\n",
      "Drift pushed\n",
      "Creating pull request\n",
      "Pull request created: https://github.com/Samox/data-history/pull/155\n",
      "Assignee Sammy does not exist\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "\n",
    "import datagit.drift_evaluators\n",
    "importlib.reload(datagit.drift_evaluators)\n",
    "from datagit.drift_evaluators import default_drift_evaluator\n",
    "\n",
    "\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "\n",
    "store_metric(gh_client,  ultra_large_df3, file_path, assignees=[\"Sammy\"], store_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultra_large_df.to_json(local_file_path+'.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
