{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "import os\n",
    "\n",
    "# Create a .env with the following content:\n",
    "# GH_TOKEN=your_github_token\n",
    "# REPON=$gh_org/$repo\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "# Get GitHub token from environment variable\n",
    "gh_token = os.getenv(\"GH_TOKEN\")\n",
    "if gh_token is None:\n",
    "    print(\"GitHub token not found! Create a .env file a the root with a GH_TOKEN variable.\")\n",
    "    exit(1)\n",
    "gh_client = Github(gh_token, timeout=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 unique_key        date  metric_value  \\\n",
      "0      ff9f0f4c-1e5b-4229-9559-e300621ba05c  2006-12-02          6.88   \n",
      "1      1374e72b-6d35-4156-8832-691a2650b25e  2004-06-15          7.89   \n",
      "2      ad24dcf8-f9f0-4ca0-b730-99f67cffd540  1999-02-16          2.85   \n",
      "3      2355cb2d-fd4e-40d1-a80f-2b1a1c7eb45a  2019-01-03          0.72   \n",
      "4      a046cc3d-c4ac-454d-bcc3-9a228a97943b  2022-01-25          3.58   \n",
      "...                                     ...         ...           ...   \n",
      "99995  97ec909b-2dad-4503-8fac-2ee8e3f42c4b  2003-09-01          8.04   \n",
      "99996  c3b8463c-7718-453f-8ebd-f47d3f06342f  2011-01-17          9.90   \n",
      "99997  8d78aff3-e28d-4485-a967-5651774f2c46  2020-11-25          1.66   \n",
      "99998  ef946185-adb5-4874-88a6-ee2bb0f2e354  2000-08-27          9.86   \n",
      "99999  53a49f76-c1dc-4c48-ad3f-36f8925c9ad8  2011-05-29          4.78   \n",
      "\n",
      "      country_code    category  \n",
      "0               SZ  Category A  \n",
      "1               GY  Category C  \n",
      "2               ES  Category B  \n",
      "3               VN  Category A  \n",
      "4               BG  Category B  \n",
      "...            ...         ...  \n",
      "99995           CU  Category B  \n",
      "99996           BY  Category B  \n",
      "99997           OM  Category A  \n",
      "99998           IN  Category A  \n",
      "99999           AG  Category C  \n",
      "\n",
      "[100000 rows x 5 columns]\n",
      "Size of DataFrame in bytes: 6690051\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker to generate random data\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows for the dataframe\n",
    "num_rows = 100000\n",
    "\n",
    "# Generate random IDs and dates\n",
    "ids = [fake.uuid4() for _ in range(num_rows)]\n",
    "dates = [fake.date_between(start_date='-30y', end_date='today').strftime('%Y-%m-%d') for _ in range(num_rows)]\n",
    "\n",
    "# Generate random metric values between 0 and 10\n",
    "metric_values = [round(random.uniform(0, 10),2) for _ in range(num_rows)]\n",
    "# Generate random country codes\n",
    "country_codes = [fake.country_code() for _ in range(num_rows)]\n",
    "\n",
    "# Generate random categories\n",
    "categories = [random.choice(['Category A', 'Category B', 'Category C']) for _ in range(num_rows)]\n",
    "\n",
    "# Create the dataframe\n",
    "ultra_large_df = pd.DataFrame({'unique_key': ids, 'date': dates, 'metric_value': metric_values, 'country_code': country_codes, 'category': categories})\n",
    "\n",
    "# Print the dataframe\n",
    "print(ultra_large_df)\n",
    "local_file_path = 'ultra_large_df.csv'\n",
    "ultra_large_df.to_csv(local_file_path, index=False)\n",
    "print('Size of DataFrame in bytes:', os.path.getsize(local_file_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric not found, creating it on branch: reported\n",
      "Commit: New data: path/to/ultra_large_metric_name12.csv\n",
      "Metric stored\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "\n",
    "## Test with file already existing and splitting new data and historical data\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "file_path = repo+\"/path/to/ultra_large_metric_name12.csv\"\n",
    "store_metric(gh_client,  ultra_large_df, file_path, assignees=[\"Sammy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75721 80184 19864 76699 92991 76434 84004 80917 60767 50074]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "ultra_large_df2 = ultra_large_df.copy()\n",
    "\n",
    "# Select 10 random indices for metric value update\n",
    "random_indices_metric = np.random.choice(ultra_large_df2.index, size=10, replace=False)\n",
    "print(random_indices_metric)\n",
    "# Update metric value with random values between 0 and 10\n",
    "ultra_large_df2.loc[random_indices_metric, 'metric_value'] = [round(random.uniform(0, 10),2) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key       object\n",
       "date             object\n",
       "metric_value    float64\n",
       "country_code     object\n",
       "category         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_large_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: reported\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/reported/path/to/ultra_large_metric_name12.csv?token=ABUWFP4LXKMFOMNZXWO3EZDEWVTPI\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "dataframe length 100000\n",
      "new_dataframe len 0\n",
      "old_data_with_freshdata len 100000\n",
      "Drift detected\n",
      "comparison Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Drift evaluator failed: 'dict' object has no attribute 'reported_dataframe'\n",
      "Using default drift evaluator\n",
      "Drift evaluation: {'should_alert': True, 'message': 'Drift detected:\\n- ~~üÜï 0 addition~~\\n- ~~‚ôªÔ∏è 0 modification~~\\n- ~~üóëÔ∏è 0 deletion~~'}\n",
      "Commit: Drift: path/to/ultra_large_metric_name12.csv\n",
      "https://github.com/Samox/data-history/commit/4ac7d9f6b8be391a4154469d4367ceea2c27db8e\n",
      "https://github.com/Samox/data-history/commit/1e1b99d69797fb8ba80e351eee4bf35f9cdf9273\n",
      "Drift pushed\n",
      "Creating pull request\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "\n",
    "store_metric(gh_client,  ultra_large_df2, file_path, assignees=[\"Sammy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
