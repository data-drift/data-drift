{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "import os\n",
    "\n",
    "# Create a .env with the following content:\n",
    "# GH_TOKEN=your_github_token\n",
    "# REPON=$gh_org/$repo\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "# Get GitHub token from environment variable\n",
    "gh_token = os.getenv(\"GH_TOKEN\")\n",
    "if gh_token is None:\n",
    "    print(\"GitHub token not found! Create a .env file a the root with a GH_TOKEN variable.\")\n",
    "    exit(1)\n",
    "gh_client = Github(gh_token, timeout=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  unique_key        date  metric_value  \\\n",
      "0       9e4f5f12-fb6e-4016-871d-eb5eea6ff076  2016-01-17          0.29   \n",
      "1       4bbe12d9-8fdb-48a1-9077-61689a048def  2000-12-01          6.02   \n",
      "2       9dec416e-c033-4588-85e3-9648e9164327  2016-03-04          9.78   \n",
      "3       8442e571-5a8f-477b-9b90-f85a64193d54  2008-10-22          4.79   \n",
      "4       986f3ca8-6e12-4af3-80b7-69e0047ae84f  2000-05-26          1.15   \n",
      "...                                      ...         ...           ...   \n",
      "599995  b5898424-a220-4a9c-b338-f5a2dc6c7c71  2005-06-28          0.32   \n",
      "599996  c6e33b7f-8072-4224-99f7-5c5c8d0e39b5  2006-02-20          7.40   \n",
      "599997  66b9e8f0-6eb9-4a56-aa1e-2067896eb46c  1994-11-16          3.45   \n",
      "599998  022ddcc2-3372-4708-b295-257a502b082b  2016-02-12          2.88   \n",
      "599999  c256d003-db9b-4dad-8151-5593b3364116  2007-11-15          8.02   \n",
      "\n",
      "       country_code    category  \n",
      "0                AR  Category C  \n",
      "1                LB  Category A  \n",
      "2                SO  Category C  \n",
      "3                PL  Category B  \n",
      "4                EG  Category C  \n",
      "...             ...         ...  \n",
      "599995           GE  Category A  \n",
      "599996           UY  Category A  \n",
      "599997           CU  Category A  \n",
      "599998           MY  Category C  \n",
      "599999           HU  Category B  \n",
      "\n",
      "[600000 rows x 5 columns]\n",
      "Size of DataFrame in bytes: 40140374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker to generate random data\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows for the dataframe\n",
    "num_rows = 600000\n",
    "\n",
    "# Generate random IDs and dates\n",
    "ids = [fake.uuid4() for _ in range(num_rows)]\n",
    "dates = [fake.date_between(start_date='-30y', end_date='today').strftime('%Y-%m-%d') for _ in range(num_rows)]\n",
    "\n",
    "# Generate random metric values between 0 and 10\n",
    "metric_values = [round(random.uniform(0, 10),2) for _ in range(num_rows)]\n",
    "# Generate random country codes\n",
    "country_codes = [fake.country_code() for _ in range(num_rows)]\n",
    "\n",
    "# Generate random categories\n",
    "categories = [random.choice(['Category A', 'Category B', 'Category C']) for _ in range(num_rows)]\n",
    "\n",
    "# Create the dataframe\n",
    "ultra_large_df = pd.DataFrame({'unique_key': ids, 'date': dates, 'metric_value': metric_values, 'country_code': country_codes, 'category': categories})\n",
    "\n",
    "# Print the dataframe\n",
    "print(ultra_large_df)\n",
    "local_file_path = 'ultra_large_df.csv'\n",
    "ultra_large_df.to_csv(local_file_path, index=False)\n",
    "print('Size of DataFrame in bytes:', os.path.getsize(local_file_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: reported\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/reported/path/to/ultra_large_metric_name13.csv?token=ABUWFPY65DKE55CIQTZN4CLEWVVVO\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Branch metric/path-to-ultra-large-metric-name13-csv doesn't exist, creating it...\n",
      "comparison Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No drift detected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "\n",
    "## Test with file already existing and splitting new data and historical data\n",
    "repo = os.getenv(\"REPO\") or \"gh_org/repo\"\n",
    "file_path = repo+\"/path/to/ultra_large_metric_name13.csv\"\n",
    "store_metric(gh_client,  ultra_large_df, file_path, assignees=[\"Sammy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4242  60608 392832  41643 464234 122681  10258 199077 303125 520722]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "ultra_large_df2 = ultra_large_df.copy()\n",
    "\n",
    "# Select 10 random indices for metric value update\n",
    "random_indices_metric = np.random.choice(ultra_large_df2.index, size=10, replace=False)\n",
    "print(random_indices_metric)\n",
    "# Update metric value with random values between 0 and 10\n",
    "ultra_large_df2.loc[random_indices_metric, 'metric_value'] = [round(random.uniform(0, 10),2) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key       object\n",
       "date             object\n",
       "metric_value    float64\n",
       "country_code     object\n",
       "category         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_large_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing metric...\n",
      "Metric found, updating it on branch: reported\n",
      "Content https://raw.githubusercontent.com/Samox/data-history/reported/path/to/ultra_large_metric_name13.csv?token=ABUWFP6464EDFCKTVPPS7EDEWVVWY\n",
      "Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "Old Dataframe dtypes {'unique_key': string[python], 'date': string[python], 'metric_value': string[python], 'country_code': string[python], 'category': string[python]}\n",
      "comparison                                      metric_value      \n",
      "                                             self other\n",
      "unique_key                                             \n",
      "00eb7e35-d14e-498a-83f2-037990df6cde         7.61  6.07\n",
      "01e0629f-fbec-4c91-9622-a80faf101ed7         3.83  3.81\n",
      "557b60a5-3e1f-4f9e-aa66-826a34609977         7.58  8.41\n",
      "60ca30ac-0160-4541-a286-d87420c0c89c          3.9  7.73\n",
      "7a2699c5-7bef-4ebc-96ce-4d0b82ce9ecb         7.15  2.14\n",
      "9fb4093e-c5ca-40e7-8672-30c9fa58dcdc         5.44  0.65\n",
      "af3ade69-be24-4a5a-a46b-143fd0191abd         6.71  1.42\n",
      "af59515f-d888-4e12-8486-b15e2522d6fd          2.4  7.31\n",
      "c868c90d-06d4-4ec1-b49f-9ab221ff3cb9         9.65  3.07\n",
      "e71a2664-277b-42ec-8a79-71682352d352         8.67  6.02\n",
      "Drift detected\n",
      "Drift evaluation: {'should_alert': True, 'message': 'Drift detected:\\n- ~~üÜï 0 addition~~\\n- ‚ôªÔ∏è 10 modifications\\n- ~~üóëÔ∏è 0 deletion~~'}\n",
      "Commit: Drift: path/to/ultra_large_metric_name13.csv\n",
      "https://github.com/Samox/data-history/commit/16aac0d0663dedfdeb580db9e8719adb3d3295e4\n",
      "https://github.com/Samox/data-history/commit/420673db90cce1c71f44745310d3dad81a46d5b5\n",
      "Drift pushed\n",
      "Creating pull request\n",
      "Pull request created: https://github.com/Samox/data-history/pull/149\n",
      "Assignee Sammy does not exist\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "\n",
    "import datagit.drift_evaluators\n",
    "importlib.reload(datagit.drift_evaluators)\n",
    "from datagit.drift_evaluators import default_drift_evaluator\n",
    "\n",
    "\n",
    "import datagit.github_connector\n",
    "importlib.reload(datagit.github_connector)\n",
    "from datagit.github_connector import store_metric\n",
    "\n",
    "\n",
    "store_metric(gh_client,  ultra_large_df2, file_path, assignees=[\"Sammy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
