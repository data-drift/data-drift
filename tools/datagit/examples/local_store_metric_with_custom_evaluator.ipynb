{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "\n",
    "sys.path.append('.')\n",
    "from dataset import generate_dataframe\n",
    "\n",
    "\n",
    "\n",
    "dataframe = generate_dataframe(10000)\n",
    "metric_name = \"mrr_light_3\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing table mrr_light_3 in db /Users/sammyteillet/.datadrift/default\n"
     ]
    }
   ],
   "source": [
    "from datagit.drift_evaluators import alert_drift\n",
    "import datagit.local_connector\n",
    "importlib.reload(datagit.local_connector)\n",
    "from datagit.local_connector import store_table\n",
    "drift_evaluator = alert_drift\n",
    "\n",
    "store_table(table_name=metric_name,table_dataframe=dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import insert_drift\n",
    "\n",
    "drifted_dataset =    insert_drift(dataframe, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing table mrr_light_3 in db /Users/sammyteillet/.datadrift/default\n",
      "jfsdkjfhksdjhfk\n",
      "Drift evaluator failed: MyDriftEvaluator is not implemented\n",
      "Using default drift evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/drift_evaluators.py\", line 113, in safe_drift_evaluator\n",
      "    drift_evaluation = drift_evaluator(data_drift_context)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/9r/55k5q9b53676pnrpch95mjlc0000gn/T/ipykernel_87105/3930521925.py\", line 10, in compute_drift_evaluation\n",
      "    raise Exception(\"MyDriftEvaluator is not implemented\")\n",
      "Exception: MyDriftEvaluator is not implemented\n"
     ]
    }
   ],
   "source": [
    "from datagit.drift_evaluators import DriftEvaluation, DriftEvaluatorAbstractClass, DriftEvaluatorContext\n",
    "\n",
    "\n",
    "class MyDriftEvaluator(DriftEvaluatorAbstractClass):\n",
    "    @staticmethod\n",
    "    def compute_drift_evaluation(\n",
    "        data_drift_context: DriftEvaluatorContext\n",
    "    ) -> DriftEvaluation:\n",
    "        print(\"jfsdkjfhksdjhfk\")\n",
    "        raise Exception(\"MyDriftEvaluator is not implemented\")\n",
    "\n",
    "\n",
    "store_table(table_name=metric_name,table_dataframe=drifted_dataset, drift_evaluator=MyDriftEvaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       13.00\n",
      "1       10.96\n",
      "2        4.15\n",
      "3        6.87\n",
      "4        2.76\n",
      "        ...  \n",
      "9995     4.28\n",
      "9996     7.95\n",
      "9997     4.64\n",
      "9998    10.55\n",
      "9999     9.78\n",
      "Name: metric_value3, Length: 10000, dtype: float64\n",
      "Storing table mrr_light_3 in db /Users/sammyteillet/.datadrift/default\n",
      "Is there a breakdown\n"
     ]
    }
   ],
   "source": [
    "drifted_dataset['metric_value2'] = drifted_dataset['metric_value'] + 1\n",
    "drifted_dataset.loc[0, \"metric_value\"] = 12\n",
    "drifted_dataset['metric_value3'] = (drifted_dataset['metric_value'] + 1).round(2)\n",
    "drifted_dataset.drop(columns=['metric_value2'], inplace=True)\n",
    "print(drifted_dataset['metric_value3'])\n",
    "\n",
    "store_table(table_name=metric_name,table_dataframe=drifted_dataset, drift_evaluator=MyDriftEvaluator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
