{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dbt_valid_from\n",
      "0                        NaT\n",
      "1 2023-10-25 14:40:13.772308\n",
      "2 2023-10-25 14:41:27.131453\n",
      "Processing data for date: 2023-10-25 14:41:27.131453\n",
      "                                 unique_key booking_date metric_value  \\\n",
      "0      63228a3e-18e6-4cf8-b809-ab7bb4ec4f2f   2023-09-07         4.31   \n",
      "1      92b3d319-968e-42f7-9c26-d397d118cf94   2023-01-08         8.17   \n",
      "2      f9ce25a8-9104-45de-8d20-2b12350dad9a   2023-03-12         8.34   \n",
      "3      73f57f5c-8763-4cc2-8e85-51c8aed210bd   2023-07-26         8.86   \n",
      "4      c38f587a-dfc2-4be2-bc88-e0b6998eae7c   2023-05-21         1.15   \n",
      "...                                     ...          ...          ...   \n",
      "60095  f5546a15-2329-427a-a2c5-88db07923085   2023-01-22         7.94   \n",
      "60096  f8234a54-2ab4-4dec-b659-e921742e36ee   2023-05-25         2.89   \n",
      "60097  f856b3e5-c279-4057-8e8f-8a95011b6e62   2023-01-04         1.88   \n",
      "60098  fd69e3f3-facb-4bc9-89b6-51b8a012a0cd   2022-11-20         7.42   \n",
      "60099  fda643c5-7a9f-444f-8b9c-725a4634dc3b   2023-01-18         5.07   \n",
      "\n",
      "      country_code                  created_at                  updated_at  \\\n",
      "0               MM  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "1               KG  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "2               NE  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "3               BT  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "4               ER  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "...            ...                         ...                         ...   \n",
      "60095           SO  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "60096           FJ  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "60097           CL  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "60098           AT  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "60099           SA  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "\n",
      "             date  \n",
      "0      2023-09-07  \n",
      "1      2023-01-08  \n",
      "2      2023-03-12  \n",
      "3      2023-07-26  \n",
      "4      2023-05-21  \n",
      "...           ...  \n",
      "60095  2023-01-22  \n",
      "60096  2023-05-25  \n",
      "60097  2023-01-04  \n",
      "60098  2022-11-20  \n",
      "60099  2023-01-18  \n",
      "\n",
      "[60100 rows x 7 columns]\n",
      "Storing metric bookings_snapshot in db /Users/sammyteillet/.datadrift/default\n",
      "Processing data for date: 2023-10-25 14:40:13.772308\n",
      "                                 unique_key booking_date metric_value  \\\n",
      "0      63228a3e-18e6-4cf8-b809-ab7bb4ec4f2f   2023-09-07         4.31   \n",
      "1      92b3d319-968e-42f7-9c26-d397d118cf94   2023-01-08         8.17   \n",
      "2      f9ce25a8-9104-45de-8d20-2b12350dad9a   2023-03-12         8.34   \n",
      "3      73f57f5c-8763-4cc2-8e85-51c8aed210bd   2023-07-26         8.86   \n",
      "4      c38f587a-dfc2-4be2-bc88-e0b6998eae7c   2023-05-21         1.15   \n",
      "...                                     ...          ...          ...   \n",
      "59995  cc195836-aa39-4817-8181-afe099361b32   2023-03-28          6.2   \n",
      "59996  f0debd1e-eee1-4fcf-8bb4-c90966353d1b   2023-01-09         0.44   \n",
      "59997  dc3a8d20-ac7a-450a-84f7-0e6cd70ea3d1   2023-06-30         1.26   \n",
      "59998  13f3a90b-7779-46c0-ab73-1adfb8a8b01b   2023-06-01         3.15   \n",
      "59999  166a73b0-6ac7-4a97-bc9b-3c4a97669fcf   2023-04-28         2.84   \n",
      "\n",
      "      country_code                  created_at                  updated_at  \\\n",
      "0               MM  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "1               KG  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "2               NE  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "3               BT  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "4               ER  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "...            ...                         ...                         ...   \n",
      "59995           NP  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "59996           KM  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "59997           PY  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "59998           BT  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "59999           SE  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "\n",
      "             date  \n",
      "0      2023-09-07  \n",
      "1      2023-01-08  \n",
      "2      2023-03-12  \n",
      "3      2023-07-26  \n",
      "4      2023-05-21  \n",
      "...           ...  \n",
      "59995  2023-03-28  \n",
      "59996  2023-01-09  \n",
      "59997  2023-06-30  \n",
      "59998  2023-06-01  \n",
      "59999  2023-04-28  \n",
      "\n",
      "[60000 rows x 7 columns]\n",
      "Storing metric bookings_snapshot in db /Users/sammyteillet/.datadrift/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/dataframe_update_breakdown.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  step2 = pd.concat([step1, new_data[step1.columns]], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for date: NaT\n",
      "                                 unique_key booking_date metric_value  \\\n",
      "0      63228a3e-18e6-4cf8-b809-ab7bb4ec4f2f   2023-09-07         4.31   \n",
      "1      92b3d319-968e-42f7-9c26-d397d118cf94   2023-01-08         8.17   \n",
      "2      f9ce25a8-9104-45de-8d20-2b12350dad9a   2023-03-12         8.34   \n",
      "3      73f57f5c-8763-4cc2-8e85-51c8aed210bd   2023-07-26         8.86   \n",
      "4      c38f587a-dfc2-4be2-bc88-e0b6998eae7c   2023-05-21         1.15   \n",
      "...                                     ...          ...          ...   \n",
      "59995  f5546a15-2329-427a-a2c5-88db07923085   2023-01-22         7.94   \n",
      "59996  f8234a54-2ab4-4dec-b659-e921742e36ee   2023-05-25         2.89   \n",
      "59997  f856b3e5-c279-4057-8e8f-8a95011b6e62   2023-01-04         1.88   \n",
      "59998  fd69e3f3-facb-4bc9-89b6-51b8a012a0cd   2022-11-20         7.42   \n",
      "59999  fda643c5-7a9f-444f-8b9c-725a4634dc3b   2023-01-18         5.07   \n",
      "\n",
      "      country_code                  created_at                  updated_at  \\\n",
      "0               MM  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "1               KG  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "2               NE  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "3               BT  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "4               ER  2023-10-25 14:40:13.772308  2023-10-25 14:40:13.772308   \n",
      "...            ...                         ...                         ...   \n",
      "59995           SO  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "59996           FJ  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "59997           CL  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "59998           AT  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "59999           SA  2023-10-25 14:40:13.772308  2023-10-25 14:41:27.131453   \n",
      "\n",
      "             date  \n",
      "0      2023-09-07  \n",
      "1      2023-01-08  \n",
      "2      2023-03-12  \n",
      "3      2023-07-26  \n",
      "4      2023-05-21  \n",
      "...           ...  \n",
      "59995  2023-01-22  \n",
      "59996  2023-05-25  \n",
      "59997  2023-01-04  \n",
      "59998  2022-11-20  \n",
      "59999  2023-01-18  \n",
      "\n",
      "[60000 rows x 7 columns]\n",
      "Storing metric bookings_snapshot in db /Users/sammyteillet/.datadrift/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammyteillet/Documents/Projects/DataDrift/data-drift/tools/datagit/datagit/dataframe_update_breakdown.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  step2 = pd.concat([step1, new_data[step1.columns]], axis=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import datagit.local_connector\n",
    "importlib.reload(datagit.local_connector)\n",
    "from datagit.local_connector import store_metric\n",
    "\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "engine = create_engine('postgresql://sammyteillet@localhost:5432/dbt-dummy-project')\n",
    "\n",
    "snapshot_table = \"bookings_snapshot\"\n",
    "date_column = \"booking_date\"\n",
    "unique_key = \"unique_key\"\n",
    "\n",
    "text_query = f\"\"\"\n",
    "SELECT DISTINCT dbt_valid_from FROM {snapshot_table}\n",
    "UNION\n",
    "SELECT DISTINCT dbt_valid_to FROM {snapshot_table};\n",
    "\"\"\"\n",
    "query = text(text_query)\n",
    "df = pd.read_sql(query, engine)\n",
    "print(df)\n",
    "\n",
    "for index, row in df.iloc[::-1].iterrows():\n",
    "    date = row['dbt_valid_from']\n",
    "    print(f\"Processing data for date: {date}\")\n",
    "    if(pd.isna(date)):\n",
    "        date = pd.Timestamp.now()\n",
    "\n",
    "    \n",
    "    asOfQuery = f\"\"\"\n",
    "    SELECT * FROM {snapshot_table}\n",
    "    WHERE ('{date}' BETWEEN dbt_valid_from AND dbt_valid_to) OR\n",
    "          (dbt_valid_to IS NULL AND dbt_valid_from <= '{date}');\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch data that's valid for the given snapshot date\n",
    "    data_as_of_date = pd.read_sql(text(asOfQuery), engine)\n",
    "\n",
    "    data_as_of_date.replace({np.nan: 'NA'}, inplace=True)\n",
    "\n",
    "    # Drop dbt columns and add date and unique_key columns\n",
    "    data_as_of_date = data_as_of_date.drop(['dbt_scd_id', 'dbt_updated_at', 'dbt_valid_from', 'dbt_valid_to'], axis=1)\n",
    "    data_as_of_date[\"date\"] = data_as_of_date[date_column]\n",
    "    data_as_of_date[\"unique_key\"] = data_as_of_date[unique_key]\n",
    "    data_as_of_date = data_as_of_date.astype(str)\n",
    "    print(data_as_of_date)\n",
    "\n",
    "    store_metric(metric_name=snapshot_table, metric_value=data_as_of_date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
